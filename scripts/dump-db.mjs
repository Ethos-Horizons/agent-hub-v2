// Minimal Postgres schema dumper (no Docker, no pg_dump)
// Usage:
// 1) Create a file at project root named .env.db with:
//    DATABASE_URL=postgresql://postgres:yourpassword@db.xxx.supabase.co:5432/postgres?sslmode=require
// 2) Run: npm run db:dump

import fs from 'node:fs';
import path from 'node:path';
import postgres from 'postgres';

// Load DATABASE_URL from .env.db if present
const envFile = path.resolve('.env.db');
if (fs.existsSync(envFile)) {
  const lines = fs.readFileSync(envFile, 'utf8').split(/\r?\n/);
  for (const line of lines) {
    const m = /^\s*DATABASE_URL\s*=\s*(.+)\s*$/.exec(line);
    if (m) process.env.DATABASE_URL = m[1].trim();
  }
}

const connectionString = process.env.DATABASE_URL;
if (!connectionString) {
  console.error('DATABASE_URL not set. Create .env.db or export env var.');
  process.exit(1);
}

const outDir = path.resolve('DATABASE/remote');
fs.mkdirSync(outDir, { recursive: true });

const sql = postgres(connectionString, { ssl: 'require' });

function mapPolicyCmd(cmd) {
  // Maps single-letter policy commands to SQL keywords
  return cmd === 'r' ? 'SELECT'
    : cmd === 'a' ? 'INSERT'
    : cmd === 'w' ? 'UPDATE'
    : cmd === 'd' ? 'DELETE'
    : cmd === '*' ? 'ALL'
    : 'ALL';
}

function qident(name) {
  return /[^a-z0-9_]/i.test(name) ? '"' + name.replace(/"/g, '""') + '"' : name;
}

function mapType(row) {
  if (row.data_type === 'USER-DEFINED') return row.udt_name; // enums
  // Basic mapping for common types
  return row.udt_name;
}

async function main() {
  const schemaObj = { enums: [], tables: {} };

  // Enums
  const enums = await sql`
    SELECT t.typname AS enum_name,
           string_agg(e.enumlabel, ',' ORDER BY e.enumsortorder) AS labels
    FROM pg_type t
    JOIN pg_enum e ON t.oid = e.enumtypid
    JOIN pg_namespace n ON n.oid = t.typnamespace
    WHERE n.nspname = 'public'
    GROUP BY t.typname
    ORDER BY t.typname;
  `;

  for (const e of enums) {
    schemaObj.enums.push({ name: e.enum_name, labels: e.labels.split(',') });
  }

  // Tables
  const tables = await sql`
    SELECT table_name
    FROM information_schema.tables
    WHERE table_schema = 'public' AND table_type = 'BASE TABLE'
    ORDER BY table_name;
  `;

  for (const t of tables) {
    const table = t.table_name;
    // Columns
    const columns = await sql`
      SELECT column_name, data_type, udt_name, is_nullable, column_default
      FROM information_schema.columns
      WHERE table_schema = 'public' AND table_name = ${table}
      ORDER BY ordinal_position;
    `;

    // Primary key
    const pks = await sql`
      SELECT kcu.column_name
      FROM information_schema.table_constraints tc
      JOIN information_schema.key_column_usage kcu
        ON tc.constraint_name = kcu.constraint_name
       AND tc.table_schema = kcu.table_schema
      WHERE tc.table_schema = 'public' AND tc.table_name = ${table} AND tc.constraint_type = 'PRIMARY KEY'
      ORDER BY kcu.ordinal_position;
    `;

    // Foreign keys
    const fks = await sql`
      SELECT conname, pg_get_constraintdef(c.oid) AS definition
      FROM pg_constraint c
      JOIN pg_class t ON c.conrelid = t.oid
      JOIN pg_namespace n ON n.oid = t.relnamespace
      WHERE n.nspname = 'public' AND t.relname = ${table} AND c.contype = 'f'
      ORDER BY conname;
    `;

    // Indexes
    const indexes = await sql`
      SELECT indexname, indexdef
      FROM pg_indexes
      WHERE schemaname = 'public' AND tablename = ${table}
      ORDER BY indexname;
    `;

    // Policies & RLS
    const policies = await sql`
      SELECT p.policyname, p.cmd, p.permissive,
             p.qual AS using,
             p.with_check AS with_check
      FROM pg_policies p
      JOIN pg_class c ON c.relname = p.tablename
      JOIN pg_namespace n ON n.oid = c.relnamespace AND n.nspname = p.schemaname
      WHERE p.schemaname = 'public' AND p.tablename = ${table}
      ORDER BY p.policyname;
    `;
    const rls = await sql`
      SELECT relrowsecurity, relforcerowsecurity
      FROM pg_class
      WHERE relname = ${table} AND relnamespace = 'public'::regnamespace;
    `;

    schemaObj.tables[table] = { columns, pks: pks.map(r => r.column_name), fks, indexes, policies, rls: rls[0] || null };
  }

  // Write JSON summary
  const summaryPath = path.join(outDir, 'schema.summary.json');
  fs.writeFileSync(summaryPath, JSON.stringify(schemaObj, null, 2));

  // Generate minimal SQL
  const lines = [];
  lines.push('-- Generated by scripts/dump-db.mjs (lightweight schema export)');
  lines.push('');
  for (const e of schemaObj.enums) {
    const labels = e.labels.map(l => ` '${l.replace(/'/g, "''")}'`).join(',');
    lines.push(`DO $$ BEGIN CREATE TYPE ${qident(e.name)} AS ENUM(${labels}); EXCEPTION WHEN duplicate_object THEN NULL; END $$;`);
  }
  lines.push('');

  for (const [table, t] of Object.entries(schemaObj.tables)) {
    lines.push(`CREATE TABLE IF NOT EXISTS public.${qident(table)} (`);
    const colLines = t.columns.map((c) => {
      const nullable = c.is_nullable === 'YES' ? '' : ' NOT NULL';
      const def = c.column_default ? ` DEFAULT ${c.column_default}` : '';
      return `  ${qident(c.column_name)} ${mapType(c)}${nullable}${def}`;
    });
    if (t.pks.length > 0) {
      colLines.push(`  PRIMARY KEY (${t.pks.map(qident).join(', ')})`);
    }
    lines.push(colLines.join(',\n'));
    lines.push(');');
    lines.push('');

    for (const fk of t.fks) {
      lines.push(`ALTER TABLE public.${qident(table)} ADD CONSTRAINT ${qident(fk.conname)} ${fk.definition};`);
    }
    if (t.fks.length) lines.push('');

    for (const ix of t.indexes) {
      lines.push(ix.indexdef + ';');
    }
    if (t.indexes.length) lines.push('');

    if (t.rls?.relrowsecurity) {
      lines.push(`ALTER TABLE public.${qident(table)} ENABLE ROW LEVEL SECURITY;`);
      if (t.rls.relforcerowsecurity) {
        lines.push(`ALTER TABLE public.${qident(table)} FORCE ROW LEVEL SECURITY;`);
      }
    }
    for (const p of t.policies) {
      const forCmd = mapPolicyCmd(p.cmd);
      const using = p.using ? ` USING (${p.using})` : '';
      const withCheck = p.with_check ? ` WITH CHECK (${p.with_check})` : '';
      lines.push(`CREATE POLICY ${qident(p.policyname)} ON public.${qident(table)} FOR ${forCmd}${using}${withCheck};`);
    }
    if (t.policies.length) lines.push('');
  }

  const sqlPath = path.join(outDir, 'schema.sql');
  fs.writeFileSync(sqlPath, lines.join('\n'));

  // Data export (NDJSON per table)
  const dataDir = path.join(outDir, 'data');
  fs.mkdirSync(dataDir, { recursive: true });
  const manifest = {};
  for (const t of tables) {
    const table = t.table_name;
    const filePath = path.join(dataDir, `${table}.ndjson`);
    const stream = fs.createWriteStream(filePath);
    let count = 0;
    // Unsafe is acceptable here because table names are discovered from information_schema
    const rows = await sql.unsafe(`SELECT * FROM public."${table}"`);
    for (const row of rows) {
      stream.write(JSON.stringify(row) + '\n');
      count += 1;
    }
    stream.end();
    manifest[table] = { rows: count, file: path.relative(process.cwd(), filePath) };
  }
  const manifestPath = path.join(outDir, 'data.manifest.json');
  fs.writeFileSync(manifestPath, JSON.stringify(manifest, null, 2));

  await sql.end();
  console.log(`Wrote:\n - ${path.relative(process.cwd(), summaryPath)}\n - ${path.relative(process.cwd(), sqlPath)}\n - ${path.relative(process.cwd(), manifestPath)}\n - ${path.relative(process.cwd(), path.join(outDir, 'data'))}`);
}

main().catch((e) => {
  console.error('Dump failed:', e);
  process.exit(1);
});


